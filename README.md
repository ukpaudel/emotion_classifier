# Summary

**emotion_classifier** is a modular, production-ready Python framework for speech emotion classification. It leverages powerful self-supervised speech encoders (like Wav2Vec2 or HuBERT) with an attention-based classifier on top, allowing easy transfer learning and fine-tuning for emotion recognition tasks.

It is designed to be configuration-driven, making training, evaluation, and experimentation easy and reproducible.

---

## ðŸš€ Features

- ðŸ”Œ Plug-and-play support for self-supervised encoders (tested with HuBERT, Wav2Vec2)
- â„ï¸ Encoder freezing or selective fine-tuning of the last *N* layers (`unfreeze_last_n_layers`)
- ðŸ§© Dynamic masking support for variable-length audio
- ðŸ—‚ï¸ Extensible to new datasets â€” just add a new dataset loader like `ravdess_dataset.py`
- ðŸ’¾ Pretrained weight loading with `pretrained_weights.enabled: true`
- ðŸ“ TensorBoard integration and logging for visualization
- ðŸ”„ Checkpoint-based resume functionality
- ðŸŽ¯ Supports single-file inference and real-time emotion detection with ASR
- ðŸ› Automatic saving of misclassified audio samples for inspection (Need to update)
- ðŸ› ï¸ Configurable entirely through `configs/config.yml`

---
## Install Dataset
RAVDESS: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio
Download and extract it into data/ravdess/data/actor_1, actor_2, etc. 
## Folder Structure

emotion_classifier/
â”œâ”€â”€ configs/
â”‚ â””â”€â”€ config.yml
â”‚ â””â”€â”€ models_runs.yml
â”‚ â””â”€â”€ inference_config.yml

â”œâ”€â”€ data/
â”‚ â””â”€â”€ ravdess_dataset.py
â”‚ â””â”€â”€ cremad_dataset.py
â”‚ â””â”€â”€ dataloader.py
â”‚ â””â”€â”€ collate.py
â”‚ â””â”€â”€ ravdess
    â””â”€â”€ data/
  â””â”€â”€ CREMA-D
    â””â”€â”€ data/
â”œâ”€â”€ models/
â”‚ â””â”€â”€ attention_classifier.py
â”‚ â””â”€â”€ emotion_model.py
â”œâ”€â”€ runs/
â”‚ â””â”€â”€ emotion_classifier_v#
â”‚   â””â”€â”€ run_label #stored based on config file logging.run_label   
â”‚       â””â”€â”€ checkpoint.pt #This is the store weights from the training
â”‚       â””â”€â”€ events.out.tfevents. #stores tensorboard info
â”‚ â””â”€â”€ example_comparisons.png
â”‚ â””â”€â”€ encoder_loader.py
â”‚ â””â”€â”€ run_tracker.py
â”‚ â””â”€â”€ model_utils.py
â”‚ â””â”€â”€ tensorboard_plot_utils.py
â”œâ”€â”€ train/
â”‚ â””â”€â”€ trainer.py
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ config.py
â”‚ â””â”€â”€ logger.py
â”‚ â””â”€â”€ encoder_loader.py
â”‚ â””â”€â”€ run_tracker.py
â”‚ â””â”€â”€ model_utils.py
â”‚ â””â”€â”€ tensorboard_plot_utils.py
â”œâ”€â”€ inference/
â”‚ â””â”€â”€ realtime_inference_withASR.py
â”œâ”€â”€ run_experiment.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â””â”€â”€ ...


## Architecture
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚         Waveform Input        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Self-Supervised Encoder      â”‚
               â”‚   (Wav2Vec2, HuBERT, WavLM)   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚    Variable-Length Features   â”‚
               â”‚  (sequence of 768-dim tokens) â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                       (with optional mask)
                              â”‚
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚     Attention Pooling         â”‚
               â”‚   (weighted average pooling)  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Feedforward Classifier (MLP) â”‚
               â”‚    (with Dropout + GELU)      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚       Emotion Logits          â”‚
               â”‚      (one of 8 classes)       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



## âš™ï¸ Installation

```bash
git clone https://github.com/ukpaudel/emotion_classifier.git
cd emotion_classifier
pip install -e .

```

## Usage

### Training

```
>cd emotion_classifier
>python .\run_experiment.py 

This will read parameters from configs/config.yml, including:
encoder type
dataset path
hyperparameters
output directories
resume or pretrained settings

```
### Visualize Comparisons Between Different Experiments
To Visualize Tensboard Weights go to bash and run ```  > tensorboard --logdir=runs and open http://localhost:6006/ ```

### Inference 
For realtime
To run go to the root folder ```cd emotion_classifier\emotion_classifier```  
``` > python .\inference\realtime_inference_withASR.py```

for single audio
``` > python .\inference\realtime_inference_withASR.py```

## Results.
see comparison between different trainings in 
```runs\example_comparisons.png``` file. 
Verdict: mixed results. Saw as high as closer to 80% classification accuracy with RAVDAV dataset. Adding CREMA-D dataset made the classification accuracy go hover around 70%. Unfreezing the encoder layers gave inconsistent results, for RAVDAV dataset, it increased the efficiency significantly, though I am concerned that the validation dataset was too small and the model was overfitting.
Wav2Vec2 had poorer performance. HuBert results in increase classification accuracy with model converging with fewer epoches.

## Author
Uttam Paudel
paudeluttam@gmail.com

## License

[MIT](https://choosealicense.com/licenses/mit/)